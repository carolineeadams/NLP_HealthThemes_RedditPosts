{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164852b0",
   "metadata": {},
   "source": [
    "## Caroline Adams\n",
    "## Clustering and Predicting Themes in Reddit Health Posts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a95c3cd",
   "metadata": {},
   "source": [
    "The dataset I am using for this analysis was compiled by Naseem et al. (2022) and contains health-related content from 15 subreddits on Reddit focused on health, daily activities, and fun. Using an API, the authors collected 10,015 unique posts from January 1, 2015, through March 19, 2021. The authors labeled each post as one of three categories: figurative health mention (FHM; discussing health terms and topics figuratively or hyperbolically, not literally), nonpersonal health mention (NPHM; discussion of health condition/symptoms generally), and personal health mention (PHM; discussion of health condition/symptoms in relation to a person). The authors have made this dataset publicly available on GitHub, however, the subreddit and time origination of each post was not included in this public version.\n",
    "\n",
    "I used the dataset from Naseem et al. (2022) to see if text prediction methods could accurately distinguish between posts that talk about health metaphorically and those that discuss the health of actual people. Text clustering was performed using the K-means algorithm, resulting in four clusters focused on general chronic health conditions and symptoms, Alzheimer’s disease, allergic reactions, and heart attacks. Each cluster contained a mixture of personal, non-personal, and figurative health mentions, indicating that the clustering algorithm did not match the categorizations completed by Naseem et al. (2022). Prediction efforts utilized the K Nearest Neighbors and Naïve Bayes algorithms to predict whether a post used health terms literally or not. \n",
    "\n",
    "The code for this analysis is included below.\n",
    "\n",
    "The writeup of the findings can be found in the accompanying report, \"Clustering and Predicting Themes in Reddit Health Posts.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29764f",
   "metadata": {},
   "source": [
    "## Setup & Descriptive Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for analysis\n",
    "\n",
    "#data wrangling\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plotting & visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, validation_curve, learning_curve, train_test_split\n",
    "from sklearn.metrics import confusion_matrix     \n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold # Cross validation \n",
    "from sklearn.model_selection import cross_validate # Cross validation \n",
    "from sklearn.model_selection import GridSearchCV # Cross validation + param. tuning.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3df07",
   "metadata": {},
   "source": [
    "### Obtaining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e443e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in dataset from github\n",
    "hmc=pd.read_csv(\"https://raw.githubusercontent.com/usmaann/RHMD-Health-Mention-Dataset/main/RHMD_3_Class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d31a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examining top rows of dataset\n",
    "hmc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d037ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing for missing data\n",
    "hmc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bc085",
   "metadata": {},
   "source": [
    "### Table 1 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating how many posts there are per label\n",
    "hmc['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7417e",
   "metadata": {},
   "source": [
    "### Figure 1 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60932a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating a new variable for post length\n",
    "hmc['length'] = hmc.apply(lambda row: len(row.Text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a629aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby label and calculate average post length\n",
    "hmc_len=hmc.groupby(by='Label').agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn label into categorical variable\n",
    "hmc_len[\"Label\"] = hmc_len[\"Label\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot average post length by label\n",
    "\n",
    "#set figure size\n",
    "plt.figure(figsize=(10,7))\n",
    "#initiate bar plot \n",
    "plt.bar(hmc_len['Label'], hmc_len['length'])\n",
    "#set x axis ticks\n",
    "plt.xticks(np.arange(3), (\"Figurative Mentions\",\"Non-Personal Mentions\", \"Personal Mentions\"))\n",
    "#add x axis label\n",
    "plt.xlabel(\"Health Content Category\")\n",
    "#add y axis label\n",
    "plt.ylabel(\"Character Count\")\n",
    "#add title\n",
    "plt.title(\"Length of Posts by Content Category\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(\"length_bar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb9610",
   "metadata": {},
   "source": [
    "### Figure 2 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn text column into a list\n",
    "text_list=hmc['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all items in list with commas in between \n",
    "text_join=\",\".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c49cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word cloud for all words in all posts\n",
    "wordcloud=WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color=\"steelblue\", scale=4)\n",
    "wordcloud.generate(text_join)\n",
    "wordcloud.to_image()\n",
    "#wordcloud.to_file(\"wordcloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd98fdb",
   "metadata": {},
   "source": [
    "### Tables 2-4 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba000eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually list top health terms identified from word cloud\n",
    "cloud_keywords=[\"feel\", \"depression\", \"ptsd\", \"heart attack\", \"headache\", \"cancer\", \"asthma\", \"allergic\", \"treatment\", \"sick\", \"stroke\", \"fever\", \"ocd\", \"help\", \"diabetes\", \"symptom\", \"cough\", \"died\", \"diagnosed\", \"alzheimer\", \"live\", \"sleep\", \"coughing\", \"brain\", \"migraine\", \"die\", \"anxiety\", \"drug\", \"cat\", \"mental health\", \"pain\", \"addiction\", \"body\", \"covid\", \"risk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually reorganize terms into lists of diseases, symptoms, and other\n",
    "diseases=['covid', \"addiction\", \"mental health\", \"anxiety\", \"alzheimer\", \"depression\", \"diabetes\", \"ocd\", \"ptsd\", \"asthma\", \"cancer\", \"stroke\", \"heart attack\", \"allergic\"]\n",
    "symptoms=['pain', \"coughing\", \"cough\", \"symptom\", \"fever\", \"sick\", \"headache\", \"feel\", \"migraine\"]\n",
    "other=['body', \"risk\", \"cat\", \"drug\", \"die\", \"brain\", \"sleep\", \"live\", \"diagnosed\", \"died\", \"help\", \"treatment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d2e5a",
   "metadata": {},
   "source": [
    "### Table 2 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c93f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set empty list to capture disease term\n",
    "count_dis=[]\n",
    "\n",
    "#for loop to count how often disease terms appeared\n",
    "for term in diseases:\n",
    "    count=0\n",
    "    for text in text_list:\n",
    "        if term in text:\n",
    "            count+=1\n",
    "    count_dis.append(count)\n",
    "    terms.append(term)\n",
    "\n",
    "#create data frame for just frequency of disease terms\n",
    "count_dis_df= pd.DataFrame(list(zip(diseases, count_dis)),\n",
    "               columns =['Condition Term', 'Frequency'])\n",
    "#display terms\n",
    "count_dis_df            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e19a0",
   "metadata": {},
   "source": [
    "### Table 3 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set empty list to capture symptom terms\n",
    "count_sym=[]\n",
    "\n",
    "#for loop to count frequency of symptom terms\n",
    "for term in symptoms:\n",
    "    count=0\n",
    "    for text in text_list:\n",
    "        if term in text:\n",
    "            count+=1\n",
    "    count_sym.append(count)\n",
    "    terms.append(term)\n",
    "\n",
    "#new df of frequencies of symptom terms only\n",
    "count_sym_df= pd.DataFrame(list(zip(symptoms, count_sym)),\n",
    "               columns =['Symptom Term', 'Frequency'])\n",
    "#display df\n",
    "count_sym_df             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a24d71",
   "metadata": {},
   "source": [
    "### Table 4 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list to capture other terms\n",
    "count_other=[]\n",
    "\n",
    "#for loop to count frequency of other terms in all posts\n",
    "for term in other:\n",
    "    count=0\n",
    "    for text in text_list:\n",
    "        if term in text:\n",
    "            count+=1\n",
    "    count_other.append(count)\n",
    "    terms.append(term)\n",
    "\n",
    "#create new df for frequency of other terms only\n",
    "count_other_df= pd.DataFrame(list(zip(other, count_other)),\n",
    "               columns =['Other Health Term', 'Frequency'])\n",
    "\n",
    "#display df\n",
    "count_other_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8764b",
   "metadata": {},
   "source": [
    "### Figures 3-5 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4928e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn label column into a list\n",
    "label_list=hmc['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists to capture counts of terms for each text\n",
    "count_list=[]\n",
    "terms=[]\n",
    "texts=[]\n",
    "\n",
    "#iterate through each post and each health term to calculate frequency\n",
    "for text in text_list:\n",
    "    for term in cloud_keywords:\n",
    "        count=0\n",
    "        terms.append(term)\n",
    "        texts.append(text)\n",
    "        if term in text:\n",
    "                count+=1\n",
    "        count_list.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df with each text, each health term, and its frequency\n",
    "health_term_freq = pd.DataFrame(list(zip(texts, terms, count_list)),\n",
    "               columns =['Text',\"Term\", 'Frequency'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge original dataset onto text-term df to include labels\n",
    "health_term_freq_merge=health_term_freq.merge(hmc,on='Text',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby term and label, sum variables, and reset inex\n",
    "health_term_freq_merge=health_term_freq_merge.groupby( [ \"Term\", \"Label\"] ).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set label to categorical variable\n",
    "health_term_freq_merge[\"Label\"] = health_term_freq_merge[\"Label\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename labels\n",
    "health_term_freq_merge['Label']=health_term_freq_merge['Label'].replace([0, 1, 2], [\"Figurative Mention\", \"Non-Personal Mention\", \"Personal Mention\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30a1d1",
   "metadata": {},
   "source": [
    "### Figure 3 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate grouped bar chart\n",
    "phm_chart = alt.Chart(health_term_freq_merge[health_term_freq_merge['Label']==\"Personal Mention\"]).mark_bar(color=\"orange\").encode(\n",
    "    x=alt.X('Term:N', sort=\"-y\"),\n",
    "    y=\"Frequency:Q\").properties(\n",
    "    title='Top Health-Related Words in Personal Health Mention Posts'\n",
    ")\n",
    "\n",
    "#display chart\n",
    "phm_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda3f55",
   "metadata": {},
   "source": [
    "### Figure 4 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f52a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate groupbed bar chart\n",
    "nphm_chart = alt.Chart(health_term_freq_merge[health_term_freq_merge['Label']==\"Non-Personal Mention\"]).mark_bar(color=\"pink\").encode(\n",
    "    x=alt.X('Term:N', sort=\"-y\"),\n",
    "    y=\"Frequency:Q\").properties(\n",
    "    title='Top Health-Related Words in Non-Personal Health Mention Posts'\n",
    ")\n",
    "\n",
    "#display chart\n",
    "nphm_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bceae1",
   "metadata": {},
   "source": [
    "### Figure 5 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate groupbed bar chart\n",
    "fhm_chart = alt.Chart(health_term_freq_merge[health_term_freq_merge['Label']==\"Figurative Mention\"]).mark_bar().encode(\n",
    "    x=alt.X('Term:N', sort=\"-y\"),\n",
    "    y=\"Frequency:Q\").properties(\n",
    "    title='Top Health-Related Words in Figurative Health Mention Posts'\n",
    ")\n",
    "\n",
    "#display chart\n",
    "fhm_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea8a5a",
   "metadata": {},
   "source": [
    "## TF-IDF Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876a563",
   "metadata": {},
   "source": [
    "### Apendix Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set empty lists to capture number of features and min df\n",
    "num_feat_list=[]\n",
    "min_df_list=[]\n",
    "\n",
    "#iterate through 30 times and calculate the number of features for each min df\n",
    "#append values to lists above\n",
    "for i in range(30):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=i, stop_words='english')  #initialize tf idf vectorizer\n",
    "    tfidf = tfidf_vectorizer.fit_transform(text_list)  #fit vectorizer to text list\n",
    "    num_feat=tfidf.shape[1]  #pull part of shape that represents number of features\n",
    "    num_feat_list.append(num_feat)  #append num features to list\n",
    "    min_df_list.append(i)  #append min df number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of results of iteration\n",
    "mindf_df=pd.DataFrame()\n",
    "mindf_df['num_feat']=num_feat_list\n",
    "mindf_df['min_df']=min_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of features by min df values\n",
    "\n",
    "#set x axis values\n",
    "x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23, 24, 25, 26, 27, 28, 29, 30]\n",
    "x_axis = np.arange(len(x))\n",
    "plt.figure(figsize=(10,7))  #set fig size\n",
    "plt.scatter(mindf_df['min_df'], mindf_df['num_feat'])  #initiate scatter plot\n",
    "plt.xticks(x_axis, x)  #plot x ticks\n",
    "plt.xlabel(\"Minimum Document Frequency\")  #add x axis label\n",
    "plt.ylabel(\"Number of Features\")  #add y axis label\n",
    "plt.title(\"Number of Features by Minimum Document Frequency\")  #add title\n",
    "plt.show()  #show plot\n",
    "#plt.savefig(\"FeatureReduction.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create document term matrix using tfidf\n",
    "#initiate vectorizer instance\n",
    "#remove stop words\n",
    "#remove tokens that are numbers only\n",
    "#set min df to 10\n",
    "vector = TfidfVectorizer(stop_words='english', min_df=10, token_pattern=\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\")\n",
    "\n",
    "#fit vectorizer to text data\n",
    "dtm = vector.fit_transform(hmc['Text'])\n",
    "\n",
    "#calculate shape of document term matrix\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a15be3",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38901d23",
   "metadata": {},
   "source": [
    "### Appendix Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set range of 2 through 10\n",
    "k_vals = range(2,11)\n",
    "inert = []  #create empty list to capture inertia values\n",
    "silh = [] #create empty list to capture silhouette scores\n",
    "\n",
    "for i in k_vals:\n",
    "    km = KMeans(init='k-means++', n_clusters=i, max_iter=300,n_init=10)  #initiate instance of kmeans\n",
    "    inert.append(km.fit(dtm).inertia_)  #fit to dtm and pull inertia value\n",
    "    silh.append(silhouette_score(dtm, km.fit_predict(dtm), metric='euclidean'))  #fit to dtm and pull silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7429a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set x axis values and range\n",
    "x=[0, 1,2,3,4,5,6,7,8,9,10]\n",
    "x_axis = np.arange(len(x))\n",
    "\n",
    "plt.figure(figsize=(10,7))  #set fig size\n",
    "plt.plot(k_vals, inert)  #plot k values versus inertia values\n",
    "plt.xticks(x_axis, x)  #plot x ticks\n",
    "plt.xlabel('Number of Clusters (K)')  #add x axis label\n",
    "plt.ylabel('SSE')  #add y axis label\n",
    "plt.xlim(1,)  #set x axis limit\n",
    "plt.title('Sum of Squared Errors (SSE) versus Number of Clusters')  #add title\n",
    "plt.show()\n",
    "#plt.savefig(\"Kmeans-SSE.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c6c6f",
   "metadata": {},
   "source": [
    "### Figure 6 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27253fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot values of k against silhouette scores\n",
    "plt.plot(k_vals, silh)\n",
    "plt.xticks(x_axis, x)  #add x ticks and labels\n",
    "plt.xlabel('Number of Clusters')  #add x axis label\n",
    "plt.ylabel('Silhouette Score')  #add y axis label\n",
    "plt.title('Silhouette Score Versus Number of Clusters')  #add plot title\n",
    "plt.xlim(1,11)  #set x axis limit\n",
    "plt.show()\n",
    "#plt.savefig(\"Silhouette_clusteringKMeans.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f82c3b",
   "metadata": {},
   "source": [
    "### Cluster Analysis When K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate instance of k-means algorithm with n clusters = 3 and fit to DTM\n",
    "clus_labels3 = KMeans(init='k-means++', n_clusters=3, n_init=10, random_state=0).fit_predict(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900558b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with each post and its assigned cluster label\n",
    "cluster_df3 = pd.DataFrame({'text':hmc['Text'], 'cluster':clus_labels3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f61e8",
   "metadata": {},
   "source": [
    "### Table 5 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of documents in each cluster\n",
    "cluster_df3['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc6669",
   "metadata": {},
   "source": [
    "### Table 6 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters3 = [cluster_df3[cluster_df3['cluster']==i] for i in np.arange(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e18d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that takes in documents and number of words\n",
    "def top_words(documents, num_words):\n",
    "    \"\"\"Accepts a vector of documents and returns the specified number of words with \n",
    "    the highest average tfidf score\"\"\"\n",
    "    #apply TFIDF weighting\n",
    "    vect = TfidfVectorizer(stop_words='english')\n",
    "    #fit weighting to documents\n",
    "    dtm = vect.fit_transform(documents)\n",
    "    #get list of terms\n",
    "    term_indices = {index: term for term, index in vect.vocabulary_.items()}\n",
    "    #set terms as column names\n",
    "    colterms = [term_indices[i] for i in range(dtm.shape[1])]\n",
    "    #create df\n",
    "    dtm_df = pd.DataFrame(dtm.toarray(), columns=colterms)\n",
    "    #aggregate by mean and sort, return head of list based on number of words set\n",
    "    return dtm_df.agg('mean').sort_values(ascending=False).head(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e47dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print list of top 20 words in each cluster\n",
    "for c in clusters3:\n",
    "    print(top_words(c['text'], 20), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd9585",
   "metadata": {},
   "source": [
    "### Cluster Analysis When K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate instance of k-means algorithm with n clusters = 4\n",
    "clus_labels4 = KMeans(init='k-means++', n_clusters=4, n_init=10, random_state=0).fit_predict(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with each post and its assigned cluster label\n",
    "cluster_df4 = pd.DataFrame({'text':hmc['Text'], 'cluster':clus_labels4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a8ea4",
   "metadata": {},
   "source": [
    "### Table 5 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of documents in each cluster\n",
    "cluster_df4['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b20f0",
   "metadata": {},
   "source": [
    "### Table 6 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ac5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters4 = [cluster_df4[cluster_df4['cluster']==i] for i in np.arange(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a97432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print list of top 20 words in each cluster\n",
    "for c in clusters4:\n",
    "    print(top_words(c['text'], 20), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd891a8",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20389204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse personal and non personal health mentions into one class\n",
    "hmc['Label'].replace(2, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate class counts\n",
    "hmc['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b133e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary of term indices\n",
    "vect.vocabulary_\n",
    "term_indices = {index: term for term, index in vect.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column name list of terms in term_indices\n",
    "colterms = [term_indices[i] for i in range(dtm.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature matrix of terms\n",
    "X = pd.DataFrame(dtm.toarray(), columns=colterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set label equal to y as target array\n",
    "y = hmc['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853baaa7",
   "metadata": {},
   "source": [
    "### Figure 7 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee269f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating validation curve for K\n",
    "\n",
    "# Setting the range for the parameter k\n",
    "parameter_range = [5,10,15,20,25]\n",
    "\n",
    "# Calculate accuracy on training and test set using the\n",
    "# n_neighbors parameter with 5-fold cross validation\n",
    "train_score, test_score = validation_curve(KNeighborsClassifier(), X, y,\n",
    "                                       param_name = \"n_neighbors\",\n",
    "                                       param_range = parameter_range,\n",
    "                                        cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "# Calculating mean and standard deviation of training score\n",
    "mean_train_score = np.mean(train_score, axis = 1)\n",
    "\n",
    "# Calculating mean and standard deviation of testing score\n",
    "mean_test_score = np.mean(test_score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean accuracy scores for training and testing scores\n",
    "plt.plot(parameter_range, mean_train_score,\n",
    "     label = \"Training Score\", color = 'r')\n",
    "plt.plot(parameter_range, mean_test_score,\n",
    "   label = \"Testing Score\", color = 'b')\n",
    "\n",
    "# Creating the plot\n",
    "plt.title(\"Validation Curve with K Nearest Neighbors Classifier\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlim(4,)\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('validation_curve.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting train test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b082fb1",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69417cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knn algorithms\n",
    "knn_all = KNeighborsClassifier(n_neighbors=15)  #for cross validation\n",
    "\n",
    "knn_all.fit(Xtrain, ytrain)  #fit to X and y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply five-fold cross validation using just training data\n",
    "scores_knn = cross_val_score(knn_all,\n",
    "                         Xtrain,\n",
    "                         ytrain,\n",
    "                         cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all five scores from each fold\n",
    "for i, each in enumerate(scores_knn):\n",
    "    print(f\"CV {i+1}, accuracy score: {each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa57c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean score across 5 folds\n",
    "print(f\"Mean CV accuracy score: {scores_knn.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating predictions using test data\n",
    "y_preds_knn = knn_all.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51d552",
   "metadata": {},
   "source": [
    "### Table 8 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2703d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing a confusion matrix for the knn model\n",
    "#putting into a dataframe and displaying the matrix\n",
    "pd.DataFrame(confusion_matrix(ytest, y_preds_knn),\n",
    "            columns=[\"Predicted negative\", \"Predicted positive\"],\n",
    "            index=[\"Actual negative\",\"Actual positive\"]).style.background_gradient(cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c6bd8",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc98bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate Naive Bayes model for cross validation\n",
    "nb = MultinomialNB()\n",
    "#fit to X and y training data\n",
    "nb.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe551fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply five-fold cross validation to NB model\n",
    "scores_nb = cross_val_score(nb,\n",
    "                         Xtrain,\n",
    "                         ytrain,\n",
    "                         cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all five scores from each fold\n",
    "for i, each in enumerate(scores_nb):\n",
    "    print(f\"CV {i+1}, accuracy score: {each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean score across 5 folds\n",
    "print(f\"Mean CV accuracy score: {scores_nb.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f5fef",
   "metadata": {},
   "source": [
    "### Table 9 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating predictions using test data\n",
    "y_preds_nb = nb.predict(Xtest)\n",
    "\n",
    "#computing a confusion matrix for the NB model\n",
    "#putting into a dataframe and displaying the matrix\n",
    "pd.DataFrame(confusion_matrix(ytest, y_preds_nb))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(ytest, y_preds_nb),\n",
    "            columns=[\"Predicted Figurative\", \"Predicted Literal\"],\n",
    "            index=[\"Actual Figurative\",\"Actual Literal\"]).style.background_gradient(cmap=\"PiYG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
